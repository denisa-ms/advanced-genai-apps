{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LLMs for Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON, Markdown, Image\n",
    "import textwrap\n",
    "\n",
    "load_dotenv()\n",
    "AISTUDIO_AZURE_OPENAI_KEY = os.getenv(\"AISTUDIO_AZURE_OPENAI_KEY\")\n",
    "AISTUDIO_AZURE_OPENAI_ENDPOINT = os.getenv(\"AISTUDIO_AZURE_OPENAI_ENDPOINT\")\n",
    "AISTUDIO_OPENAI_GPT4_DEPLOYMENT_NAME = os.getenv(\"AISTUDIO_OPENAI_GPT4_DEPLOYMENT_NAME\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = AISTUDIO_AZURE_OPENAI_ENDPOINT, \n",
    "  api_key=AISTUDIO_AZURE_OPENAI_KEY,  \n",
    "  api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openAI(text):\n",
    "    system_message = \"\"\"\n",
    "    The user will enter a question and the possible results from the search query. Please rank these results by relevance to the search query.\n",
    "    Please answer in JSON format using the schema below.\n",
    "\n",
    "    schema:\n",
    "    {\n",
    "        \"documents\": {\n",
    "            \"document 1\": \"Relevance\",\n",
    "            \"document 2\": \"Relevance\", \n",
    "            ...\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=AISTUDIO_OPENAI_GPT4_DEPLOYMENT_NAME,\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":system_message},\n",
    "            {\"role\":\"user\",\"content\":text }\n",
    "            ],\n",
    "        temperature=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def prettyprint(text: str) -> str:\n",
    "    print(textwrap.fill(text, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "```json\n",
       "{\n",
       "    \"documents\": {\n",
       "        \"document 3\": \"High\",\n",
       "        \"document 2\": \"Medium\",\n",
       "        \"document 5\": \"Low\",\n",
       "        \"document 1\": \"Irrelevant\",\n",
       "        \"document 4\": \"Irrelevant\"\n",
       "    }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_results = \"\"\"\n",
    "Search Results:\n",
    "[Document 1] Paul loved going for walks with Mr. McChicken\n",
    "[Document 2] Paul saw his colleague eat a juicy McDonald’s McChicken burger\n",
    "[Document 3] Paul loved to eat McDonald’s McChicken burger\n",
    "[Document 4] Paul always had dinner with Mrs. McChicken\n",
    "[Document 5] Paul had a lot of lettuce in his salad\n",
    "\"\"\"\n",
    "question = \" Question : What did Paul love to eat? \"\n",
    "answer = call_openAI(question + search_results)\n",
    "display(HTML(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
