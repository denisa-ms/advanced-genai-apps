{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with prompty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Learning Objectives** - Upon completing this tutorial, you should be able to:\n",
    "\n",
    "- Write LLM application using prompty and visualize the trace of your application.\n",
    "- batch run prompty against multi lines of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install dependent packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "#\n",
    "%%capture --no-stderr\n",
    "%pip install promptflow-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute a Prompty\n",
    "\n",
    "Prompty is a file with .prompty extension for developing prompt template. \n",
    "The prompty asset is a markdown file with a modified front matter. \n",
    "The front matter is in yaml format that contains a number of metadata fields which defines model configuration and expected inputs of the prompty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"basic.prompty\") as fin:\n",
    "    print(fin.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: before running below cell, please configure required environment variable `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` by create an `.env` file. Please refer to `../.env.example` as an template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#create a .env file with the following variables and replace with your values\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_GPT4_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_DEPLOYMENT_NAME\")\n",
    "AZURE_SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "AZURE_AISTUDIO_PROJECT_RESOURCE_GROUP = os.getenv(\"AZURE_AISTUDIO_PROJECT_RESOURCE_GROUP\")\n",
    "AZURE_AISTUDIO_PROJECT_NAME = os.getenv(\"AZURE_AISTUDIO_PROJECT_NAME\")\n",
    "api_version = \"2024-02-15-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I can't provide real-time pricing or availability for products like the Trailwalker hiking shoes. Prices can vary based on the retailer, location, sales, and other factors. To find the current price, please check with online retailers, local stores, or the official website of the brand that offers the Trailwalker hiking shoes.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from promptflow.core import Prompty\n",
    "\n",
    "# load prompty as a flow\n",
    "f = Prompty.load(source=\"basic.prompty\")\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the price for the Trailwalker hiking shoes?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can override configuration with `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I can't provide real-time pricing or availability for products like the Trailwalker hiking shoes. Prices can vary based on the retailer, location, sales, and other factors. To find the current price, please check with online retailers, local stores, or the official website of the brand that offers the Trailwalker hiking shoes.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
    "\n",
    "# override configuration with AzureOpenAIModelConfiguration - in this case I am using the same model just to show how to use it\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=\"${env:AZURE_OPENAI_ENDPOINT}\",  # Use ${env:<ENV_NAME>} to surround the environment variable name.\n",
    "    api_key=\"${env:AZURE_OPENAI_API_KEY}\",\n",
    "    azure_deployment=\"gpt-4\",\n",
    ")\n",
    "\n",
    "# override configuration with OpenAIModelConfiguration\n",
    "# configuration = OpenAIModelConfiguration(\n",
    "#     base_url=\"${env:OPENAI_BASE_URL}\",\n",
    "#     api_key=\"${env:OPENAI_API_KEY}\",\n",
    "#     model=\"gpt-3.5-turbo\"\n",
    "# )\n",
    "\n",
    "override_model = {\"configuration\": configuration, \"parameters\": {\"max_tokens\": 512}}\n",
    "\n",
    "# load prompty as a flow\n",
    "f = Prompty.load(source=\"basic.prompty\", model=override_model)\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the price for the Trailwalker hiking shoes?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize trace by using start_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=basic&uiTraceId=0x2130568faeb8adb86d7ff6cae8ff63aa\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=basic&uiTraceId=0x800912fbf8415ac2752b8d88e0181f27\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=basic&uiTraceId=0x4fe7328976dd234804d2f05ef06c49da\n"
     ]
    }
   ],
   "source": [
    "from promptflow.tracing import start_trace\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run below cell will collect a trace in trace UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerun the function, which will be recorded in the trace\n",
    "question = \"What is the capital of Japan?\"\n",
    "ground_truth = \"Tokyo\"\n",
    "result = f(question=question)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval the result \n",
    "\n",
    "Note: the eval flow returns a `json_object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': '5', 'explanation': 'Tokyo is the capital of Japan'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load prompty as a flow\n",
    "eval_flow = Prompty.load(\"eval.prompty\")\n",
    "# execute the flow as function\n",
    "result = eval_flow(question=question, ground_truth=ground_truth, answer=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Batch run with multi-line data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# batch run requires promptflow-devkit package\n",
    "%pip install promptflow-devkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.client import PFClient\n",
    "\n",
    "pf = PFClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-11 09:10:25 +0300][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run basic_20240911_091024_803379, log path: C:\\Users\\dschlesinger\\.promptflow\\.runs\\basic_20240911_091024_803379\\logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=basic_20240911_091024_803379\n",
      "2024-09-11 09:10:26 +0300   45388 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-09-11 09:10:34 +0300   45388 execution.bulk     INFO     Current system's available memory is 20052.01171875MB, memory consumption of current process is 204.83203125MB, estimated available worker count is 20052.01171875/204.83203125 = 97\n",
      "2024-09-11 09:10:34 +0300   45388 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3, 'estimated_worker_count_based_on_memory_usage': 97}.\n",
      "2024-09-11 09:10:37 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(8188)-Line number(0) start execution.\n",
      "2024-09-11 09:10:37 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26392)-Line number(1) start execution.\n",
      "2024-09-11 09:10:37 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(28264)-Line number(2) start execution.\n",
      "2024-09-11 09:10:41 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(8188)-Line number(0) completed.\n",
      "2024-09-11 09:10:41 +0300   45388 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2024-09-11 09:10:41 +0300   45388 execution.bulk     INFO     Average execution time for completed lines: 4.04 seconds. Estimated time for incomplete lines: 8.08 seconds.\n",
      "2024-09-11 09:10:42 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-2)-Process id(26392)-Line number(1) completed.\n",
      "2024-09-11 09:10:42 +0300   45388 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2024-09-11 09:10:42 +0300   45388 execution.bulk     INFO     Average execution time for completed lines: 2.52 seconds. Estimated time for incomplete lines: 2.52 seconds.\n",
      "2024-09-11 09:10:43 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(28264)-Line number(2) completed.\n",
      "2024-09-11 09:10:43 +0300   45388 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2024-09-11 09:10:43 +0300   45388 execution.bulk     INFO     Average execution time for completed lines: 2.02 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-09-11 09:10:43 +0300   45388 execution.bulk     INFO     The thread monitoring the process [26392-SpawnProcess-2] will be terminated.\n",
      "2024-09-11 09:10:43 +0300   45388 execution.bulk     INFO     The thread monitoring the process [28264-SpawnProcess-4] will be terminated.\n",
      "2024-09-11 09:10:43 +0300   45388 execution.bulk     INFO     The thread monitoring the process [8188-SpawnProcess-3] will be terminated.\n",
      "2024-09-11 09:10:43 +0300   28264 execution.bulk     INFO     The process [28264] has received a terminate signal.\n",
      "2024-09-11 09:10:43 +0300    8188 execution.bulk     INFO     The process [8188] has received a terminate signal.\n",
      "\n",
      "2024-09-11 09:10:44 +0300   45388 execution.bulk     INFO     Process 26392 terminated.\n",
      "2024-09-11 09:10:44 +0300   45388 execution.bulk     INFO     Process 8188 terminated.\n",
      "2024-09-11 09:10:44 +0300   45388 execution.bulk     INFO     Process 28264 terminated.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"basic_20240911_091024_803379\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-09-11 09:10:24.802378+03:00\"\n",
      "Duration: \"0:00:19.604882\"\n",
      "Output path: \"C:\\Users\\dschlesinger\\.promptflow\\.runs\\basic_20240911_091024_803379\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flow = \"./basic.prompty\"  # path to the prompty file\n",
    "data = \"./data.jsonl\"  # path to the data file\n",
    "\n",
    "# create run with the flow and data\n",
    "base_run = pf.run(\n",
    "    flow=flow,\n",
    "    data=data,\n",
    "    column_mapping={\n",
    "        \"question\": \"${data.question}\",\n",
    "    },\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is capital of France?</td>\n",
       "      <td>0</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the meaning of life?</td>\n",
       "      <td>1</td>\n",
       "      <td>The meaning of life is a philosophical questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the planets in Sun system?</td>\n",
       "      <td>2</td>\n",
       "      <td>The planets in the Solar System, in order from...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       inputs.question  inputs.line_number  \\\n",
       "0           What is capital of France?                   0   \n",
       "1         What is the meaning of life?                   1   \n",
       "2  What are the planets in Sun system?                   2   \n",
       "\n",
       "                                      outputs.output  \n",
       "0                    The capital of France is Paris.  \n",
       "1  The meaning of life is a philosophical questio...  \n",
       "2  The planets in the Solar System, in order from...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = pf.get_details(base_run)\n",
    "details.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate your flow\n",
    "Then you can use an evaluation method to evaluate your flow. The evaluation methods are also flows which usually using LLM assert the produced output matches certain expectation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation on the previous batch run\n",
    "The **base_run** is the batch run we completed in step 2 above, for web-classification flow with \"data.jsonl\" as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-11 09:11:34 +0300][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run basic_20240911_091134_555794, log path: C:\\Users\\dschlesinger\\.promptflow\\.runs\\basic_20240911_091134_555794\\logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=basic_20240911_091134_555794\n",
      "2024-09-11 09:11:34 +0300   45388 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-09-11 09:11:34 +0300   45388 execution.bulk     INFO     Current system's available memory is 19927.69921875MB, memory consumption of current process is 209.54296875MB, estimated available worker count is 19927.69921875/209.54296875 = 95\n",
      "2024-09-11 09:11:34 +0300   45388 execution.bulk     INFO     Set process count to 3 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 3, 'estimated_worker_count_based_on_memory_usage': 95}.\n",
      "2024-09-11 09:11:38 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-6)-Process id(44488)-Line number(0) start execution.\n",
      "2024-09-11 09:11:38 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-7)-Process id(31652)-Line number(1) start execution.\n",
      "2024-09-11 09:11:38 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-8)-Process id(38996)-Line number(2) start execution.\n",
      "2024-09-11 09:11:39 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-6)-Process id(44488)-Line number(0) completed.\n",
      "2024-09-11 09:11:40 +0300   45388 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2024-09-11 09:11:40 +0300   45388 execution.bulk     INFO     Average execution time for completed lines: 2.0 seconds. Estimated time for incomplete lines: 4.0 seconds.\n",
      "2024-09-11 09:11:43 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-7)-Process id(31652)-Line number(1) completed.\n",
      "2024-09-11 09:11:43 +0300   45388 execution.bulk     INFO     Process name(SpawnProcess-8)-Process id(38996)-Line number(2) completed.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     Average execution time for completed lines: 2.01 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     The thread monitoring the process [44488-SpawnProcess-6] will be terminated.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     The thread monitoring the process [31652-SpawnProcess-7] will be terminated.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     The thread monitoring the process [38996-SpawnProcess-8] will be terminated.\n",
      "2024-09-11 09:11:44 +0300   44488 execution.bulk     INFO     The process [44488] has received a terminate signal.\n",
      "2024-09-11 09:11:44 +0300   38996 execution.bulk     INFO     The process [38996] has received a terminate signal.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     Process 44488 terminated.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     Process 38996 terminated.\n",
      "2024-09-11 09:11:44 +0300   45388 execution.bulk     INFO     Process 31652 terminated.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"basic_20240911_091134_555794\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-09-11 09:11:34.554795+03:00\"\n",
      "Duration: \"0:00:10.261911\"\n",
      "Output path: \"C:\\Users\\dschlesinger\\.promptflow\\.runs\\basic_20240911_091134_555794\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_prompty = \"./eval.prompty\"\n",
    "\n",
    "eval_run = pf.run(\n",
    "    flow=eval_prompty,\n",
    "    data=\"./data.jsonl\",  # path to the data file\n",
    "    run=base_run,  # specify base_run as the run you want to evaluate\n",
    "    column_mapping={\n",
    "        \"question\": \"${data.question}\",\n",
    "        \"answer\": \"${run.outputs.output}\",  \n",
    "        \"ground_truth\": \"${data.ground_truth}\",\n",
    "    },\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.answer</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.score</th>\n",
       "      <th>outputs.explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is capital of France?</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer correctly identifies Paris as the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the meaning of life?</td>\n",
       "      <td>The meaning of life is a philosophical questio...</td>\n",
       "      <td>The meaning of life is subjective and can vary...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The answer provides a comprehensive overview o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the planets in Sun system?</td>\n",
       "      <td>The planets in the Solar System, in order from...</td>\n",
       "      <td>The planets in the Solar System are Mercury, V...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer correctly lists all eight planets o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       inputs.question  \\\n",
       "0           What is capital of France?   \n",
       "1         What is the meaning of life?   \n",
       "2  What are the planets in Sun system?   \n",
       "\n",
       "                                       inputs.answer  \\\n",
       "0                    The capital of France is Paris.   \n",
       "1  The meaning of life is a philosophical questio...   \n",
       "2  The planets in the Solar System, in order from...   \n",
       "\n",
       "                                 inputs.ground_truth  inputs.line_number  \\\n",
       "0                                              Paris                   0   \n",
       "1  The meaning of life is subjective and can vary...                   1   \n",
       "2  The planets in the Solar System are Mercury, V...                   2   \n",
       "\n",
       "   outputs.score                                outputs.explanation  \n",
       "0              5  The answer correctly identifies Paris as the c...  \n",
       "1              4  The answer provides a comprehensive overview o...  \n",
       "2              5  The answer correctly lists all eight planets o...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = pf.get_details(eval_run)\n",
    "details.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "The HTML file is generated at 'C:\\\\Users\\\\dschlesinger\\\\AppData\\\\Local\\\\Temp\\\\pf-visualize-detail-au9xu4xt.html'.\n",
      "Trying to view the result in a web browser...\n",
      "Successfully visualized from the web browser.\n"
     ]
    }
   ],
   "source": [
    "# visualize run using ui\n",
    "pf.visualize([base_run, eval_run])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "By now you've successfully run your first prompt flow and even did evaluation on it. That's great!\n",
    "\n",
    "You can check out more examples:\n",
    "- [Basic Chat](https://github.com/microsoft/promptflow/tree/main/examples/prompty/chat-basic): demonstrates how to create a chatbot that can remember previous interactions and use the conversation history to generate next message."
   ]
  }
 ],
 "metadata": {
  "build_doc": {
   "author": [
    "lalala123123@github.com",
    "wangchao1230@github.com"
   ],
   "category": "local",
   "section": "Prompty",
   "weight": 10
  },
  "description": "A quickstart tutorial to run a prompty and evaluate it.",
  "kernelspec": {
   "display_name": "prompt_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "resources": "examples/requirements.txt, examples/prompty/basic, examples/prompty/eval-basic"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
