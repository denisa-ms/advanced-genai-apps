{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# To learn more, please visit the documentation - Quickstart: Azure Content Safety: https://aka.ms/acsstudiodoc\n",
    "#\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#create a .env file with the following variables and replace with your values\n",
    "AISTUDIO_AZURE_OPENAI_KEY = os.getenv(\"AISTUDIO_AZURE_OPENAI_KEY\")\n",
    "AISTUDIO_AZURE_OPENAI_ENDPOINT = os.getenv(\"AISTUDIO_AZURE_OPENAI_ENDPOINT\")\n",
    "AISTUDIO_OPENAI_GPT4_DEPLOYMENT_NAME = os.getenv(\"AISTUDIO_OPENAI_GPT4_DEPLOYMENT_NAME\")\n",
    "AZURE_SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "AZURE_AISTUDIO_PROJECT_RESOURCE_GROUP = os.getenv(\"AZURE_AISTUDIO_PROJECT_RESOURCE_GROUP\")\n",
    "AZURE_AISTUDIO_PROJECT_NAME = os.getenv(\"AZURE_AISTUDIO_PROJECT_NAME\")\n",
    "api_version = \"2024-02-15-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "from promptflow.evals.evaluators import (\n",
    "    ChatEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    ContentSafetyChatEvaluator,\n",
    "    ContentSafetyEvaluator,\n",
    "    F1ScoreEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    HateUnfairnessEvaluator,\n",
    "    QAEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    SelfHarmEvaluator,\n",
    "    SexualEvaluator,\n",
    "    SimilarityEvaluator,\n",
    "    ViolenceEvaluator,\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize Azure OpenAI Connection with your environment variables\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=AISTUDIO_AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AISTUDIO_AZURE_OPENAI_KEY,\n",
    "    azure_deployment=AISTUDIO_OPENAI_GPT4_DEPLOYMENT_NAME,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "project_scope = {\n",
    "    \"subscription_id\": AZURE_SUBSCRIPTION_ID,\n",
    "    \"resource_group_name\": AZURE_AISTUDIO_PROJECT_RESOURCE_GROUP,\n",
    "    \"project_name\": AZURE_AISTUDIO_PROJECT_NAME,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt_groundedness': 5.0}\n",
      "{'gpt_relevance': 5.0}\n",
      "{'gpt_coherence': 5.0}\n",
      "{'gpt_fluency': 5.0}\n",
      "{'gpt_similarity': 5.0}\n",
      "{'f1_score': 0.4210526315789473}\n"
     ]
    }
   ],
   "source": [
    "# Content Quality evaluators\n",
    "\n",
    "# Groundedness\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "score = groundedness_eval(\n",
    "    answer=\"The Alpine Explorer Tent is the most waterproof.\",\n",
    "    context=\"From the our product list, the alpine explorer tent is the most waterproof. The Adventure Dining \"\n",
    "    \"Table has higher weight.\",\n",
    ")\n",
    "print(score)\n",
    "\n",
    "# Relevance\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "score = relevance_eval(\n",
    "    question=\"What is the capital of Japan?\",\n",
    "    answer=\"The capital of Japan is Tokyo.\",\n",
    "    context=\"Tokyo is Japan's capital, known for its blend of traditional culture \\\n",
    "        and technological advancements.\",\n",
    ")\n",
    "print(score)\n",
    "\n",
    "# Coherence\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "score = coherence_eval(question=\"What is the capital of Japan?\", answer=\"The capital of Japan is Tokyo.\")\n",
    "print(score)\n",
    "\n",
    "# Fluency\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "score = fluency_eval(question=\"What is the capital of Japan?\", answer=\"The capital of Japan is Tokyo.\")\n",
    "print(score)\n",
    "\n",
    "# Similarity\n",
    "similarity_eval = SimilarityEvaluator(model_config)\n",
    "score = similarity_eval(\n",
    "    question=\"What is the capital of Japan?\",\n",
    "    answer=\"The capital of Japan is Tokyo.\",\n",
    "    ground_truth=\"Tokyo is Japan's capital.\",\n",
    ")\n",
    "print(score)\n",
    "\n",
    "# F1 Score\n",
    "f1_score_eval = F1ScoreEvaluator()\n",
    "score = f1_score_eval(\n",
    "    answer=\"The capital of Japan is Tokyo.\",\n",
    "    ground_truth=\"Tokyo is Japan's capital, known for its blend of traditional culture and technological \"\n",
    "    \"advancements.\",\n",
    ")\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'violence': 'Very low', 'violence_score': 0, 'violence_reason': \"The system's response provides factual information about the capital of France without any mention or implication of violence.\"}\n",
      "{'sexual': 'Very low', 'sexual_score': 0, 'sexual_reason': \"The system's response provides a factual answer to a technical question without any sexual content.\"}\n",
      "{'self_harm': 'Very low', 'self_harm_score': 0, 'self_harm_reason': \"The system's response is providing information about the acronym HTTP, which is unrelated to self-harm. There is no self-harm-related content in this interaction.\"}\n",
      "{'hate_unfairness': 'Very low', 'hate_unfairness_score': 0, 'hate_unfairness_reason': \"The system's response provides a factual and neutral explanation of the acronym 'HTTP' without any negative sentiment, hateful or unfair language, or reference to any social groups or protected factors.\"}\n"
     ]
    }
   ],
   "source": [
    "# Content Safety evaluators\n",
    "\n",
    "# Violence\n",
    "violence_eval = ViolenceEvaluator(project_scope)\n",
    "score = violence_eval(question=\"What is the capital of France?\", answer=\"Paris.\")\n",
    "print(score)\n",
    "# {'violence': 'Very low', 'violence_score': 0, 'violence_reason': 'The interaction is a straightforward exchange of\n",
    "# information about geography. There is no mention or implication of violence.'}\n",
    "\n",
    "# Sexual\n",
    "sexual_eval = SexualEvaluator(project_scope, DefaultAzureCredential())\n",
    "score = sexual_eval(question=\"What does HTTP stand for?\", answer=\"HTTP stands for Hypertext Transfer Protocol.\")\n",
    "print(score)\n",
    "# {'sexual': 'Very low', 'sexual_score': 0, 'sexual_reason': \"The system's response is purely informational and\n",
    "# contains no sexual content or language.\"}\n",
    "\n",
    "# Self Harm\n",
    "self_harm_eval = SelfHarmEvaluator(project_scope, DefaultAzureCredential())\n",
    "score = self_harm_eval(question=\"What does HTTP stand for?\", answer=\"HTTP stands for Hypertext Transfer Protocol.\")\n",
    "print(score)\n",
    "# {'self_harm': 'Very low', 'self_harm_score': 0, 'self_harm_reason': \"The system's response is providing factual\n",
    "# information about a technical term, which is not related to self-harm.\"}\n",
    "\n",
    "# Hate Unfairness\n",
    "hate_unfairness_eval = HateUnfairnessEvaluator(project_scope, DefaultAzureCredential())\n",
    "score = hate_unfairness_eval(\n",
    "    question=\"What does HTTP stand for?\", answer=\"HTTP stands for Hypertext Transfer Protocol.\"\n",
    ")\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt_groundedness': 1.0, 'gpt_relevance': 5.0, 'gpt_coherence': 5.0, 'gpt_fluency': 5.0, 'gpt_similarity': 5.0, 'f1_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# QA Evaluator\n",
    "qa_eval = QAEvaluator(model_config=model_config)\n",
    "\n",
    "score = qa_eval(\n",
    "    question=\"Tokyo is the capital of which country?\",\n",
    "    answer=\"Japan\",\n",
    "    context=\"Tokyo is the capital of Japan.\",\n",
    "    ground_truth=\"Japan\",\n",
    ")\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'violence': 'Very low', 'violence_score': 0, 'violence_reason': \"The system's response simply provides factual information about the capital of France, which contains no violent content or references to violence.\", 'sexual': 'Very low', 'sexual_score': 0, 'sexual_reason': \"The system's response provides factual information about geography and does not contain any sexual content.\", 'self_harm': 'Very low', 'self_harm_score': 0, 'self_harm_reason': \"The system's response provides factual information unrelated to self-harm. It simply answers a geography question posed by the human.\", 'hate_unfairness': 'Very low', 'hate_unfairness_score': 0, 'hate_unfairness_reason': \"The system's response provides factual information about the capital of France, which is Paris. There is no negative sentiment, hate, or unfairness directed towards any social group or individual, nor is there any ungrounded inference of sensitive attributes. The content is neutral and purely informational.\"}\n"
     ]
    }
   ],
   "source": [
    "# Content Safety Evaluator\n",
    "content_safety_eval = ContentSafetyEvaluator(project_scope=project_scope)\n",
    "\n",
    "score = content_safety_eval(\n",
    "    question=\"What is the capital of France?\",\n",
    "    answer=\"Paris.\",\n",
    ")\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-22 10:30:30 +0300][promptflow.core._prompty_utils][ERROR] - Exception occurs: APIConnectionError: Connection error.\n",
      "[2024-09-22 10:30:30 +0300][promptflow.evals.evaluators._chat._chat][WARNING] - Evaluator _AsyncFluencyEvaluator failed for turn 1 with exception: OpenAI API hits APIConnectionError: Connection error. [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]\n",
      "[2024-09-22 10:30:34 +0300][promptflow.core._prompty_utils][ERROR] - Exception occurs: APIConnectionError: Connection error.\n",
      "[2024-09-22 10:30:34 +0300][promptflow.evals.evaluators._chat._chat][WARNING] - Evaluator _AsyncCoherenceEvaluator failed for turn 1 with exception: OpenAI API hits APIConnectionError: Connection error. [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evaluation_per_turn': {'gpt_groundedness': {'score': [5.0, 5.0]}, 'gpt_relevance': {'score': [5.0, 5.0]}, 'gpt_coherence': {'score': [5.0]}, 'gpt_fluency': {'score': [5.0]}, 'gpt_retrieval': {'score': [5.0, 5.0]}}, 'gpt_coherence': 5.0, 'gpt_fluency': 5.0, 'gpt_groundedness': 5.0, 'gpt_relevance': 5.0, 'gpt_retrieval': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Chat Evaluator        \n",
    "chat_eval = ChatEvaluator(model_config=model_config)\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the value of 2 + 2?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"2 + 2 = 4\",\n",
    "        \"context\": {\n",
    "            \"citations\": [{\"id\": \"doc.md\", \"content\": \"Information about additions: 1 + 2 = 3, 2 + 2 = 4\"}]\n",
    "        },\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of Japan?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The capital of Japan is Tokyo.\",\n",
    "        \"context\": {\n",
    "            \"citations\": [\n",
    "                {\n",
    "                    \"id\": \"doc.md\",\n",
    "                    \"content\": \"Tokyo is Japan's capital, known for its blend of traditional culture and \"\n",
    "                    \"technological advancements.\",\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "]\n",
    "score = chat_eval(conversation=conversation)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'violence': 'Very low', 'violence_score': 0.0, 'sexual': 'Very low', 'sexual_score': 0.0, 'self_harm': 'Very low', 'self_harm_score': 0.0, 'hate_unfairness': 'Very low', 'hate_unfairness_score': 0.0, 'evaluation_per_turn': {'violence': {'severity': ['Very low', 'Very low'], 'score': [0, 0], 'reason': [\"The system's response is a simple mathematical fact and does not contain any violent content or implications of violence.\", \"The system's response provides factual information about the capital of Japan without any mention or implication of violence.\"]}, 'sexual': {'severity': ['Very low', 'Very low'], 'score': [0, 0], 'reason': [\"The system's response is purely mathematical and contains no sexual content.\", \"The system's response provides factual geographical information without any sexual content.\"]}, 'self_harm': {'severity': ['Very low', 'Very low'], 'score': [0, 0], 'reason': [\"The system's response is a simple mathematical answer and does not contain any self-harm-related content.\", \"The system's response provides factual information about the capital of Japan and does not contain any self-harm-related content.\"]}, 'hate_unfairness': {'severity': ['Very low', 'Very low'], 'score': [0, 0], 'reason': [\"The system's response provides a factual mathematical answer without any reference to social groups, protected factors, or any sentiment that could be considered hateful or unfair.\", \"The system's response provides factual information about the capital of Japan without any negative sentiment, hate, or unfairness towards any social group or individual. There is no ungrounded inference of sensitive attributes or any mention of protected factors.\"]}}}\n"
     ]
    }
   ],
   "source": [
    "# Content Safety Chat Evaluator\n",
    "chat_eval = ContentSafetyChatEvaluator(project_scope=project_scope)\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the value of 2 + 2?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"2 + 2 = 4\",\n",
    "        \"context\": {\n",
    "            \"citations\": [{\"id\": \"doc.md\", \"content\": \"Information about additions: 1 + 2 = 3, 2 + 2 = 4\"}]\n",
    "        },\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of Japan?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The capital of Japan is Tokyo.\",\n",
    "        \"context\": {\n",
    "            \"citations\": [\n",
    "                {\n",
    "                    \"id\": \"doc.md\",\n",
    "                    \"content\": \"Tokyo is Japan's capital, known for its blend of traditional culture and \"\n",
    "                    \"technological advancements.\",\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "]\n",
    "score = chat_eval(conversation=conversation)\n",
    "print(score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
